{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609df11",
   "metadata": {},
   "source": [
    "# Create the dataset\n",
    "\n",
    "This notebook generates a synthetic dataset simulating large company groups (conglomerates) and their internal corporate hierarchies. This is mostly AI generated.\n",
    "\n",
    "- **50 Groups**: Each representing a conglomerate or major client.\n",
    "- **Company Trees**: Each group contains up to 200 companies structured as a non-binary tree.\n",
    "- **Hierarchy Depth**: Up to 6 levels deep, simulating parent-subsidiary structures.\n",
    "- **Columns**:\n",
    "  - `Group`: Name of the group\n",
    "  - `Name`: Company name\n",
    "  - `id`: Unique company ID\n",
    "  - `parent_id`: ID of the parent company (`None` if group root)\n",
    "  - `turnover`: Estimated revenue (100k to 5M), loosely correlated with workforce size\n",
    "  - `workers`: Number of employees (1 to 1000)\n",
    "  - `level`: Depth in the hierarchy (0 = group root)\n",
    "\n",
    "## Purpose\n",
    "\n",
    "- Simulates real-world corporate networks for UI prototyping or testing tree-based aggregations.\n",
    "- Enables interactive drill-down in web UIs via `id`/`parent_id` structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3460677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Parameters\n",
    "NUM_GROUPS = 50\n",
    "MAX_COMPANIES_PER_GROUP = 200\n",
    "MAX_CHILDREN_PER_NODE = 3\n",
    "MAX_DEPTH = 6\n",
    "ID_COUNTER = 1  # Global counter for unique company IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f873a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_turnover_and_workers():\n",
    "    workers = int(np.clip(np.random.normal(100, 100), 1, 1000))\n",
    "    turnover = int(np.clip(workers * random.uniform(500, 700), 100_000, 5_000_000))\n",
    "    return turnover, workers\n",
    "\n",
    "# Function to generate a single group's company tree using BFS\n",
    "def generate_group_tree(group_name):\n",
    "    global ID_COUNTER\n",
    "    companies = []\n",
    "\n",
    "    # Create the group root company\n",
    "    group_id = ID_COUNTER\n",
    "    ID_COUNTER += 1\n",
    "    turnover, workers = generate_turnover_and_workers()\n",
    "    root = {\n",
    "        \"Group\": group_name,\n",
    "        \"Name\": group_name,\n",
    "        \"id\": group_id,\n",
    "        \"parent_id\": None,\n",
    "        \"turnover\": turnover,\n",
    "        \"workers\": workers,\n",
    "        \"level\": 0\n",
    "    }\n",
    "    companies.append(root)\n",
    "\n",
    "    queue = deque([(group_id, 1)])  # (parent_id, depth)\n",
    "\n",
    "    while queue and len(companies) < MAX_COMPANIES_PER_GROUP:\n",
    "        parent_id, depth = queue.popleft()\n",
    "        if depth > MAX_DEPTH:\n",
    "            continue\n",
    "\n",
    "        num_children = random.randint(0, MAX_CHILDREN_PER_NODE)\n",
    "        for _ in range(num_children):\n",
    "            if len(companies) >= MAX_COMPANIES_PER_GROUP:\n",
    "                break\n",
    "            company_id = ID_COUNTER\n",
    "            ID_COUNTER += 1\n",
    "            turnover, workers = generate_turnover_and_workers()\n",
    "            company = {\n",
    "                \"Group\": group_name,\n",
    "                \"Name\": fake.company(),\n",
    "                \"id\": company_id,\n",
    "                \"parent_id\": parent_id,\n",
    "                \"turnover\": turnover,\n",
    "                \"workers\": workers,\n",
    "                \"level\": depth\n",
    "            }\n",
    "            companies.append(company)\n",
    "            queue.append((company_id, depth + 1))\n",
    "\n",
    "    return companies\n",
    "\n",
    "def create_base_dataframe(num_groups):\n",
    "    rows = []\n",
    "    for _ in range(num_groups):\n",
    "        group_name = f\"{fake.company()} Group\"\n",
    "        group_companies = generate_group_tree(group_name)\n",
    "        rows.extend(group_companies)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_list_children_column(df):\n",
    "    \"\"\"\n",
    "    Adds a 'list_children' column to the DataFrame, listing direct child IDs for each company.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input company DataFrame with 'id' and 'parent_id'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with a new 'list_children' column.\n",
    "    \"\"\"\n",
    "    # Step 1: Group all rows by parent_id → collect their IDs\n",
    "    child_map = df.groupby(\"parent_id\")[\"id\"].apply(list).to_dict()\n",
    "    # Step 2: Map each row's id to the list of children (or empty list)\n",
    "    df[\"list_children\"] = df[\"id\"].map(child_map).apply(lambda x: x if isinstance(x, list) else [])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd04c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_total_metrics(df):\n",
    "    \"\"\"\n",
    "    Adds 'total_turnover' and 'total_workers' columns to the DataFrame,\n",
    "    where each row includes the sum of its own metrics + all recursive descendants'.\n",
    "    \"\"\"\n",
    "    # Step 1: Build tree: parent_id → list of children\n",
    "    children_map = df.groupby(\"parent_id\")[\"id\"].apply(list).to_dict()\n",
    "\n",
    "    # Step 2: Initialize totals with own values\n",
    "    df[\"total_turnover\"] = df[\"turnover\"]\n",
    "    df[\"total_workers\"] = df[\"workers\"]\n",
    "\n",
    "    # Step 3: Create a lookup table by ID\n",
    "    df_index = df.set_index(\"id\")\n",
    "\n",
    "    # Step 4: Define recursive function using memoization\n",
    "    from functools import lru_cache\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def compute_totals(node_id):\n",
    "        # Start with the node’s own values\n",
    "        total_turnover = df_index.at[node_id, \"turnover\"]\n",
    "        total_workers = df_index.at[node_id, \"workers\"]\n",
    "\n",
    "        # Recursively add all children’s totals\n",
    "        for child_id in children_map.get(node_id, []):\n",
    "            child_turnover, child_workers = compute_totals(child_id)\n",
    "            total_turnover += child_turnover\n",
    "            total_workers += child_workers\n",
    "\n",
    "        return total_turnover, total_workers\n",
    "\n",
    "    # Step 5: Apply the recursive total computation\n",
    "    results = df[\"id\"].apply(lambda node_id: compute_totals(node_id))\n",
    "    df[\"total_turnover\"] = results.apply(lambda x: x[0])\n",
    "    df[\"total_workers\"] = results.apply(lambda x: x[1])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f4f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = create_base_dataframe(NUM_GROUPS)\n",
    "df_groups = add_list_children_column(df_groups)\n",
    "df_groups = add_total_metrics(df_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups[df_groups.Group==\"Russell-Cooper Group\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84427bb",
   "metadata": {},
   "source": [
    "## Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724bd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups.to_parquet(\"../data/company_groups.parquet\", index=False)\n",
    "# df_groups.to_csv(\"../data/company_groups.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taipy_41",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
